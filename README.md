# Spotify Music Skips Action Prediction

Spotify has over 190 million active users interacting with over 40 million tracks.
The goal of the challenge is to predict the likelihood of a user skipping any given song during a listening session.
Methodology
The Data
For the Prediction, Spotify supplied two main sets of information. One table has information about user listening sessions. For example:

session ID

position in the session

track ID

if the track was skipped or not

other session metadata

Note that the user sessions were all between 10 and 20 tracks long and didn’t include any identifiable information about the users.

The second table has metadata about the tracks (corresponding to the track_id feature from the session table), such as:

track duration

track popularity in the US

release year

As well as some extra features, generated by Spotify, to describe the songs, such as:

acousticness

beat strength

bounciness

danceability

The dataset also includes a set of 8 “acoustic vectors” for each track which are latent encodings that Spotify has generated for each track.

For licensing reasons, Spotify anonymize the track information, so there aren’t any data on things like track name, artist, album, or genre.

The targets in the provided dataset — whether or not the track was skipped — are balanced with about 51.7% of the tracks being skipped. So there was no need to adjust the class balances for training.

There was a surplus of data so You will be going to work with a subset of about 100k rows from the session table and the corresponding rows from the track table, which you will be going to load into a Postgres database hosted on an AWS EC2 instance. 

The database schema is shown below:

# Schema for Spotify Skip Data

Image for post
To get a sense of what a single session might look like, the following image shows a plot of a single user session as it relates to one of the features — “track loudness”, a Spotify descriptor of the song’s characteristics, not “volume” in the traditional sense — where the color indicates which tracks were skipped and not skipped.

Single Session’s Track-Skips vs Track-Loudness

Image for post
While not meaningful by itself, this illustrates how each session an be plotted against the song attributes. In this example, the user only listened to two of the first 11 tracks, and then listened to all of the remaining 9 tracks, as the loudness value decreased.

Further, in order to get a better sense of the overall distribution track attributes, I’ve plotted the distribution of a small subset of the features and highlighted where three different songs fall in the distribution (using data from the Spotify API). The three songs, from three different genres, are:

# Feature Engineering
This data is inherently sequential. The model’s skip-prediction for any given song will be based on the songs that were skipped earlier in the user listening session. Therefore, in order for my model to account for that, I added a group of features that represent the previous tracks’ audio features as well as whether or not those tracks were skipped.

# Model Selection
The target metric is accuracy, per competition guidelines.
You will be going start by baselining with a Logistic Regression model but found that it had poor accuracy. So from there, you will be moved on to tree-based models which would be less interpretable but would be able to automatically handle complex feature interactions.
